{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of fitting: 51 Pegasi b\n",
    "\n",
    "The ELODIE data and parameters used in this example notebook for 51 Peg b  are from [Birkby et al. 2017](http://doi.org/10.3847/1538-3881/aa5c87)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ravest.model import Planet, Star, Trend\n",
    "from ravest.fit import Fitter, Basis\n",
    "from ravest.param import Parameter\n",
    "import ravest.prior\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('example_data/51Pegb.txt', delimiter='\\s+', )\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,3.5))\n",
    "plt.title(\"51 Peg b ELODIE data\")\n",
    "plt.ylabel(\"Radial Velocity [m/s]\")\n",
    "plt.xlabel(\"BJD_TDB\")\n",
    "plt.errorbar(data[\"time\"], data[\"vel\"], yerr=data[\"verr\"], marker=\".\", linestyle=\"None\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = Fitter([\"b\"], Basis(\"per k e w tc\"))\n",
    "fitter.add_data(data[\"time\"], data[\"vel\"], data[\"verr\"])\n",
    "\n",
    "# Construct the params dict\n",
    "# These values will be used as your initial guess for the fit\n",
    "params = {\"per_b\": Parameter(4.23, \"d\", fixed=False),\n",
    "          \"k_b\": Parameter(60, \"m/s\", fixed=False),\n",
    "          \"e_b\": Parameter(0, \"\", fixed=True),\n",
    "          \"w_b\": Parameter(np.pi/2, \"rad\", fixed=True),\n",
    "          \"tc_b\": Parameter(2456326.9, \"d\", fixed=False),\n",
    "          \n",
    "          \"g\": Parameter(-33251.9, \"m/s\", fixed=False),\n",
    "          \"gd\": Parameter(0, \"m/s/day\", fixed=True),\n",
    "          \"gdd\": Parameter(0, \"m/s/day^2\", fixed=True),\n",
    "          \"jit\": Parameter(0, \"m/s\", fixed=True),}\n",
    "\n",
    "fitter.add_params(params)\n",
    "\n",
    "fitter.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the priors dict. Every parameter that isn't fixed requires a prior.\n",
    "priors = {\n",
    "          \"per_b\": ravest.prior.Gaussian(4.2293, 0.0011),\n",
    "          \"k_b\": ravest.prior.Uniform(0,100),\n",
    "          \"tc_b\": ravest.prior.Uniform(2456326.9-(4.2293), 2456326.9+(4.2293)),\n",
    "          \"g\": ravest.prior.Uniform(-33260, -33240),\n",
    "        }\n",
    "\n",
    "fitter.add_priors(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the `Fitter` with the data, our parameters and parameterisation, and defined priors for each of the free parameters, we can now fit the free parameters of the model to the data. First, Maximum A Posteriori (MAP) optimisation is performed to find the best-fit solution. Then, MCMC is used to explore the parameter space and estimate the parameter uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the free parameters to the data. First performs a\n",
    "samples = fitter.fit_model_to_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the MCMC is finished, the state of the `emcee` sampler has been saved into the `Fitter` object. We can therefore interact with it in the usual way to export the samples, as a a numpy array that can be passed into other functions (such as for comparing two models by calculating the Bayesian evidence - example notebook coming soon!). We can also export them into a Pandas dataframe, which keeps each parameter labelled. In both cases, we can pass in the `discard` and `thin` arguments as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results from the sampler\n",
    "samples = fitter.sampler.get_chain(discard=1000)\n",
    "\n",
    "# Get the samples as a labelled Pandas dataframe\n",
    "samples_df = fitter.get_samples_df(discard=1000, thin=1)\n",
    "samples_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it's far easier to inspect the chains visually. We can plot and optionally save the time series of the parameters in in the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.plot_chains(discard=1000, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualise the posterior parameter distributions using the `corner` module to create corner plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.plot_corner(discard=1000, save=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ravest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
